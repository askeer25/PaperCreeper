import streamlit as st
import requests
import time
from dotenv import load_dotenv
import os
from ResearchAgent import *
from llm_util import *


def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if "results" not in st.session_state:
        st.session_state.results = []
    if "scores" not in st.session_state:
        st.session_state.scores = []
    if "summary" not in st.session_state:
        st.session_state.summary = ""
    if "processing" not in st.session_state:
        st.session_state.processing = False
    if "current_page" not in st.session_state:
        st.session_state.current_page = "search"
    if "search_completed" not in st.session_state:
        st.session_state.search_completed = False


def search_papers(model: str, user_input: str, num_each_query: int = 5):
    """è°ƒç”¨ResearchAgentè¿›è¡Œè®ºæ–‡æœç´¢"""
    progress_bar = st.progress(0.0)
    status_text = st.empty()
    status_text.text("å¼€å§‹æœç´¢å’Œæ€»ç»“ã€‚")

    try:
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯å’ŒResearchAgent
        llm = LLM_client(model)
        agent = ResearchAgent(llm)

        criteria = agent.analyze_query(user_input)
        criteria.max_results = num_each_query

        progress_bar.progress(0.2)
        status_text.text(f"æå–æŸ¥è¯¢å…³é”®è¯:{criteria.keywords}")

        results = []
        for keyword in criteria.keywords:
            query = keyword
            result = get_arxiv_results(query, max_results=criteria.max_results)
            results.extend(result)

        num_first_papers = len(results)

        progress_bar.progress(0.4)
        status_text.text("æ£€ç´¢Arxivç›¸å…³è®ºæ–‡ã€‚")

        progress_bar.progress(0.6)
        status_text.text(f"å¯¹{num_first_papers}ç¯‡è®ºæ–‡è¿›è¡Œç­›é€‰å’Œæ’åºã€‚")

        # é‡æ–°æ’åºè®ºæ–‡
        papers, scores = agent._rerank_results(user_input, results)

        progress_bar.progress(0.8)
        status_text.text("ç”Ÿæˆé˜…è¯»æ€»ç»“ã€‚")

        messages = []
        for paper in papers:
            message = get_arxiv_message(paper)
            messages.append(message)
        summary = agent._generate_summary(messages, scores)

        # æ›´æ–°è¿›åº¦
        progress_bar.progress(1.0)
        status_text.text("æœç´¢å®Œæˆï¼")

        return {"results": papers, "scores": scores, "summary": summary}

    except Exception as e:
        st.error(f"æœç´¢å¤±è´¥: {str(e)}")
        return None


def show_search_page():
    """æ˜¾ç¤ºæœç´¢é¡µé¢"""
    st.title("PaperCreeper: è®ºæ–‡æ£€ç´¢åŠ©æ‰‹")
    st.markdown(
        """
## ğŸ¯ä¸»è¦åŠŸèƒ½ä»‹ç»

- æ”¯æŒè‡ªç„¶è¯­è¨€æè¿°çš„æŸ¥è¯¢ï¼Œå¹¶æ ¹æ®æŸ¥è¯¢è‡ªåŠ¨ç”Ÿæˆè‹¥å¹²æ£€ç´¢è¯ï¼Œå¤šæ¬¡è¿­ä»£ã€ä¼˜åŒ–æœç´¢ç»“æœã€‚
- æ”¯æŒå¯¹æ£€ç´¢ç»“æœè¿›è¡Œè¯„ä¼°å’Œé‡æ–°æ’åºï¼Œæå‡æ£€ç´¢è´¨é‡ã€‚
- æ”¯æŒå¯¹æ£€ç´¢è®ºæ–‡è¿›è¡Œé˜…è¯»å’Œæ€»ç»“ï¼Œå¹¶ç”Ÿæˆç‹¬ç‰¹è§è§£ï¼Œæ–¹ä¾¿ç”¨æˆ·å¿«é€Ÿèšç„¦æœ‰ç”¨çš„è®ºæ–‡ã€‚
"""
    )

    # æ¨¡å‹é€‰æ‹©
    st.header("ğŸ¤– è¯·é€‰æ‹©LLMæ¨¡å‹")
    model = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        [
            "openai/gpt-4o-2024-11-20",
            "openai/gpt-4o-mini-2024-07-18",
            "deepseek/deepseek-r1",
            "deepseek/deepseek-chat",
        ],
        label_visibility="collapsed",
    )

    # æŸ¥è¯¢è¾“å…¥
    st.header("ğŸ” è¯·è¾“å…¥æŸ¥è¯¢")
    st.markdown(
        """
    è¯·è¾“å…¥æ‚¨çš„è®ºæ–‡æ£€ç´¢éœ€æ±‚ (ä¸­æ–‡æˆ–è‹±æ–‡)ï¼Œå¯ä»¥åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
    - ç ”ç©¶ä¸»é¢˜æˆ–å…³é”®è¯
    - å‘è¡¨å¹´ä»½è¦æ±‚ï¼ˆå¯é€‰ï¼‰
    - ç ”ç©¶é¢†åŸŸï¼ˆå¯é€‰ï¼‰
    
    ä¾‹å¦‚ï¼š
    "Find the latest research on multi-agents for large language models."
    """
    )
    query = st.text_area("è¾“å…¥æŸ¥è¯¢", height=100, label_visibility="collapsed")

    # å¤„ç†è¿‡ç¨‹
    col1, col2 = st.columns([1, 4])
    with col1:
        search_button = st.button("å¼€å§‹æœç´¢", type="primary", use_container_width=True)

    if search_button:
        # æ‰§è¡Œæœç´¢
        result = search_papers(model, query)

        if result:
            st.session_state.results = result["results"]
            st.session_state.scores = result["scores"]
            st.session_state.summary = result["summary"]
            st.session_state.search_completed = True
            st.session_state.current_page = "results"
            st.rerun()


def show_results_page():
    """æ˜¾ç¤ºç»“æœé¡µé¢"""
    st.title("æ£€ç´¢ç»“æœ")

    # è¿”å›æœç´¢æŒ‰é’®
    if st.button("è¿”å›æœç´¢", type="secondary"):
        st.session_state.current_page = "search"
        st.session_state.search_completed = False
        st.rerun()

    # æ£€ç´¢ç»“æœ
    st.header("æ–‡çŒ®æ£€ç´¢ç»“æœ")
    if st.session_state.results:
        num_papers = len(st.session_state.results)  # resultsåŒ…å«è®ºæ–‡åˆ—è¡¨
        st.markdown(f"ä¸€å…±æ£€ç´¢å¾—åˆ°äº†{num_papers}ç¯‡ç›¸å…³è®ºæ–‡ã€‚")

        # åˆ›å»ºè¡¨æ ¼æ ‡é¢˜
        table_header = "| åºå· | æ ‡é¢˜ | å¹´ä»½ | ä½œè€… | ç›¸å…³åº¦è¯„åˆ† | ArXivé“¾æ¥ |\n| --- | --- | --- | --- | --- | --- |"
        table_rows = []

        # ä¸ºæ¯ç¯‡è®ºæ–‡åˆ›å»ºè¡¨æ ¼è¡Œ
        for i, (result, score) in enumerate(
            zip(st.session_state.results, st.session_state.scores), 1
        ):
            authors = ", ".join([author.name for author in result.authors])
            row = f"| {i} | {result.title} | {result.published.year} | {authors} | {score:.1f}/10 | [é“¾æ¥]({result.entry_id}) |"
            table_rows.append(row)

        # ç»„åˆè¡¨æ ¼
        table = "\n".join([table_header] + table_rows)
        st.markdown(table)

    # æ€»ç»“ç»“æœ
    st.header("æ–‡çŒ®é˜…è¯»æ€»ç»“ç»“æœ")
    if st.session_state.summary:
        st.markdown(st.session_state.summary)


def main():
    load_dotenv()

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    init_session_state()

    # æ ¹æ®å½“å‰é¡µé¢çŠ¶æ€æ˜¾ç¤ºä¸åŒçš„é¡µé¢
    if st.session_state.current_page == "search":
        show_search_page()
    else:
        show_results_page()


if __name__ == "__main__":
    main()
